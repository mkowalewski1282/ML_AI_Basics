{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningSolver:\n",
    "    \"\"\"Class containing the Q-learning algorithm that might be used for different discrete environments.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: int,\n",
    "        action_space: int,\n",
    "        learning_rate: float = 0.1,\n",
    "        gamma: float = 0.9,\n",
    "        epsilon: float = 0.1,\n",
    "    ):\n",
    "        self.observation_space = observation_space\n",
    "        self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def __call__(self, state: np.ndarray, action: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Return Q-value of given state and action.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def update(self, state: np.ndarray, action: np.ndarray, reward: float) -> None:\n",
    "        \"\"\"Update Q-value of given state and action.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_best_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Return action that maximizes Q-value for a given state.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Elegant representation of Q-learning solver.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
