{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_func(class_count, num_samples):\n",
    "    return (-1) * sum([count/num_samples * math.log(count/num_samples) for count in class_count.values()])\n",
    "\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, group_classes):\n",
    "        self.group_classes = group_classes\n",
    "        self.entropy = self.group_entropy()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.group_classes.size\n",
    "\n",
    "    def group_entropy(self):\n",
    "        return entropy_func(Counter(self.group_classes), len(self.group_classes))\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, split_feature, split_val, depth=None, child_node_a=None, child_node_b=None, val=None):\n",
    "        self.split_feature = split_feature\n",
    "        self.split_val = split_val\n",
    "        self.depth = depth\n",
    "        self.child_node_a = child_node_a\n",
    "        self.child_node_b = child_node_b\n",
    "        self.val = val\n",
    "\n",
    "    def predict(self, data):\n",
    "        if self.val is not None:\n",
    "            return self.val\n",
    "        elif data[self.split_feature] <= self.split_val:\n",
    "            return self.child_node_a.predict(data)\n",
    "        else:\n",
    "            return self.child_node_b.predict(data)\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_split_entropy(group_a, group_b):\n",
    "        num_samples = len(group_a) + len(group_b)\n",
    "        return group_a.entropy * (len(group_a) / num_samples) + group_b.entropy * (len(group_b) / num_samples)\n",
    "\n",
    "    def get_information_gain(self, parent_group, child_group_a, child_group_b):\n",
    "        return parent_group.entropy - self.get_split_entropy(child_group_a, child_group_b)\n",
    "\n",
    "    def get_best_feature_split(self, feature_values, classes):\n",
    "        parent_group = Group(classes)\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_split_val = None\n",
    "\n",
    "        for feature in range(len(feature_values[0])):\n",
    "            chosen_feature = feature_values[:, feature]\n",
    "            unique_values = np.unique(chosen_feature)\n",
    "            for val in unique_values:\n",
    "                group_a_idxs, group_b_idxs = self.separate_groups_by_val(chosen_feature, best_feature, val, 1)\n",
    "                group_a = Group(classes[group_a_idxs])\n",
    "                group_b = Group(classes[group_b_idxs])\n",
    "\n",
    "                gain = self.get_information_gain(parent_group, group_a, group_b)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_split_val = val\n",
    "\n",
    "        return best_feature, best_split_val\n",
    "\n",
    "    def get_best_split(self, data, classes):\n",
    "        if self.depth >= self.max_depth or len(np.unique(classes)) == 1:\n",
    "            return Node(split_feature=None, split_val=None, val=Counter(classes).most_common(1)[0][0])\n",
    "\n",
    "        best_feature, best_split_value = self.get_best_feature_split(data, classes)\n",
    "        group_a_idxs, group_b_idxs = self.separate_groups_by_val(data, best_feature, best_split_value, 2)\n",
    "\n",
    "        self.depth += 1\n",
    "        child_group_a = self.get_best_split(data[group_a_idxs], classes[group_a_idxs])\n",
    "        child_group_b = self.get_best_split(data[group_b_idxs], classes[group_b_idxs])\n",
    "\n",
    "        return Node(best_feature, best_split_value, self.depth, child_group_a, child_group_b)\n",
    "\n",
    "    def build_tree(self, data, classes, depth=0):\n",
    "        self.tree = self.get_best_split(data, classes)\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.tree.predict(data)\n",
    "\n",
    "    @staticmethod\n",
    "    def separate_groups_by_val(data, feature, value, dim):\n",
    "        temp_a_indexes = []\n",
    "        temp_b_indexes = []\n",
    "        for idx in range(len(data)):\n",
    "            if dim == 1:\n",
    "                if data[idx] <= value:\n",
    "                    temp_a_indexes.append(idx)\n",
    "                else:\n",
    "                    temp_b_indexes.append(idx)\n",
    "            elif dim == 2:\n",
    "                if data[idx, feature] <= value:\n",
    "                    temp_a_indexes.append(idx)\n",
    "                else:\n",
    "                    temp_b_indexes.append(idx)\n",
    "\n",
    "        return np.asarray(temp_a_indexes, dtype=int), np.asarray(temp_b_indexes, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2; Real class: 1\n",
      "Prediction: 2; Real class: 2\n",
      "Prediction: 2; Real class: 2\n",
      "Prediction: 1; Real class: 1\n",
      "Prediction: 0; Real class: 0\n",
      "Prediction: 2; Real class: 2\n",
      "Prediction: 1; Real class: 1\n",
      "Prediction: 0; Real class: 0\n",
      "Prediction: 0; Real class: 0\n",
      "Prediction: 1; Real class: 1\n",
      "Prediction: 2; Real class: 2\n",
      "Prediction: 0; Real class: 0\n",
      "Prediction: 1; Real class: 1\n",
      "Prediction: 2; Real class: 2\n",
      "Prediction: 2; Real class: 2\n",
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier(3)\n",
    "dc.build_tree(x_train, y_train)\n",
    "predictions = []\n",
    "for sample, gt in zip(x_test, y_test):\n",
    "    predictions.append(dc.predict(sample))\n",
    "    print(f'Prediction: {predictions[-1]}; Real class: {gt}')\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
